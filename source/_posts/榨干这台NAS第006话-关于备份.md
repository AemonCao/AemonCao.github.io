---
title: 榨干这台NAS第006话-关于备份
tags:
  - NAS
  - unRAID
  - Docker
categories:
  - '榨干这台 NAS'
date: 2025-05-30 20:55:35
description: 防患于未然。
---

这是一系列关于 NAS 的文章，系列的名称你们也看到了：「**榨干这台 NAS**」。我将尽可能详细的介绍 NAS 相关的知识，帮助你最大限度的发挥你的手中 NAS 的威力！

<!-- more -->

又拖了一年，实在惭愧。今天来讲讲备份，这两天对于把 NAS 上的重要文件都做了备份，就顺便来写一下记录记录。

### 备份的重要性

备份的重要性不言而喻，但是又只有当数据丢失时才会体会到它的重要。以下内容仅限于 NAS 上的文件备份，不包括手机和其他内容。大家可以定时先备份内容到 NAS 上。

备份是为了安全，安全分为两种，数据安全和隐私安全。

数据安全是指备份内容会不会丢失，损毁；而隐私安全是指你的备份数据会不会被窃取，被公开。对于数据内容的不同，两者的重要性也不一样。

### 常用的备份方式以及优缺点

#### 内部硬盘备份

一般较为简单的方式就是拷贝一份到别的盘或文件夹上。这就是内部硬盘（Internal HDD）备份方式。这种方式优点是：

1. 备份快捷方便，只要定时复制一份就好；

2. 成本较低，在现有硬盘空间富裕的情况下，无需多余的费用；

当然，其缺点也是显而易见的：

1. 同盘备份容易受损或感染，例如前几年开始流行的勒索病毒，它可以感染整台设备的上的文件，无一例外的你的备份也将无法幸免；

2. 空间是有限的，在需要备份的文件过大时，对应所需的硬盘空间也会变大。

#### 可移动存储媒介备份

这种方式兼顾了内部硬盘备份的方便，又保证了一定程度的安全，一般来说这也叫冷备份。方式是将需要备份的数据拷贝一份到 U 盘，移动硬盘，机械硬盘或光盘等存储介质上。并在备份完成后断电保存。其优点有：

1. 单次备份较为快捷，在进行一次性的备份时较为方便；

2. 支持异地备份，由于可移动的性质，这种方式符合 [「3-2-1 原则」](https://www.cisa.gov/sites/default/files/publications/data_backup_options.pdf) 中的 **1**，即一份拷贝保存在异地，这样当发生例如火灾等险情时，可以保证异地备份的安全。

这种方式的缺点有：

1. 对于频繁增加的数据来说，例如日常生活照片，要做到及时备份会有些困难；

2. 需要购买额外的存储设备；

3. 可移动存储媒介的不稳定性，例如 U 盘本身不适合做为长时间的冷备份，而机械硬盘对于存放条件要求又有些高。

这里介绍一下常用介质的使用场景：


| 类型                     | 特点和建议使用场景                      |
| ---------------------- | ------------------------------ |
| **外部硬盘**               | 大容量但体积大；易受物理损坏和退磁影响。           |
| **固态存储（SSD、USB）**      | 无机械部件，抗震耐用；价格高但寿命延长；常见于临时携带数据。 |
| **光盘（CD/DVD/Blu-ray）** | 容量小，便宜但寿命有限；适用于长期离线存档。         |
| **磁带**                 | 超大容量且成本低；多用于企业长期备份。            |
| **软盘/ZIP盘**            | 已淘汰，因容量太低且不再生产。                |


#### 云备份

其实大家在生活中已经有过或多或少的备份行为，例如你把旅游的照片发了朋友圈，这是一种备份；你打开了百度云的照片自动备份功能；你购买并开启了各大手机厂商自带的云服务（iCloud）……这些都是备份。

备份本质上是把重要的数据的副本保存在其他地方，上述例子中的其他地方都是指第三方厂家的服务器。

这就是我们要说的第三种备份，我通称为云备份。云备份的优点有：

1. 异地备份，服务器厂商位于各个不同城市的服务器机房，在采用多个厂商产品的备份下，完全可以保证异地备份这一项的安全性；

2. 方便，无需购买多余存储设备，现在的云盘厂商，动不动 TB 起步的容量，完全够普通人的备份需求。

缺点也是有的：

1. 依赖于网络，在第一次全量备份时，备份时间的瓶颈在上传带宽上，以目前家用的 **50Mbps** 上传带宽为例，如果需要备份 **100GB** 的数据，大概需要四个半小时。更不要说当找回数据时如果没开会员那十几 KB 的下载速度了；

2. 隐私安全没有保障，毕竟存储在第三方的服务器下，还是会存在泄露的可能，例如阿里云盘曾经有过能看到其他人照片的恶性 bug；

3. 存在厂商锁定风险，比如一些较为私密的照片非常有可能被某些云盘厂商封禁。

4. 价格，这是毋庸置疑的，毕竟厂家也不是做慈善的，既然提供了服务，就必然需要收取一定的费用，例如会员费用，或者是 OSS 存储费用和流量费用。

### 我的备份之路

接下来说说我这些年来的备份方法。

#### 手写

记得小时候充值 QB 的时候，需要去书报亭购买 QB 卡，而 30 元面值的 QB 卡背后会带有密保卡。

![密保卡.webp](https://cdn.jsdelivr.net/gh/AemonCao/AemonCao.github.io@master/source/_posts/榨干这台NAS第006话-关于备份/密保卡.webp)

当有过一次丢失的经历后，我意识到这玩意需要个备份，这时候，我就用纸笔将其写在本子上，这就成了我的第一个备份。

#### QQ 网络硬盘

但是不久之后，我遇到了问题，当我前往~~黑网吧~~时，我发现我没有将家中的密保卡带上，导致那天的我无法进入被密保卡保护的游戏。回家后，我立马将实体的卡片转录到了 Excel 上。

![Excel密保卡.png](https://cdn.jsdelivr.net/gh/AemonCao/AemonCao.github.io@master/source/_posts/榨干这台NAS第006话-关于备份/Excel密保卡.png)

并将其存在了当时的 QQ 网络硬盘（腾讯微云的前身）上，这就是我的第一个云备份。

#### [永硕 E 盘](http://www.ys168.com/)

时代的记忆，当时的各类软件和工具，一般大家都是放在这里进行分享。由于我的最初账号已经丢失，实在是无法回忆起来当时存了什么东西。

#### 千脑

只有百度百科还记录着零星的信息：<https://baike.baidu.com/item/%E5%8D%83%E8%84%91>。

#### 各类网盘

后来，网盘产品如雨后春笋般出现，手机中的照片一般都是由各大网盘的默认推荐打开的自动备份功能所备份，各位可以去看看历史较为悠久的几家网盘，说不定还能在其中找到一些你觉得早已遗失的珍贵记忆。

#### NAS

在拥有了 NAS 之后，我的大部分文件都是会拷贝到 NAS 上一份作为一个备份。但是久而久之，在看过了网上各种硬盘损坏案例后，我开始对我这一张二手企业矿盘产生了怀疑：万一哪天坏了呢？

在刚有这念头的几天里，我显得十分焦虑，总觉得下一秒硬盘就会歇菜。尤其是想到那上万张照片可能会丢失，NAS 备份刻不容缓！

### 第一版备份方案

我需要备份的文件大致分为两部分，一是数量较多但是对隐私要求不高的照片视频文件；二是数量较少但是对隐私安全较为看重的数据，例如：Vaultwarden 密码数据、Teslamate 行程数据等等。

前者量大，我使用 [Rclone](https://rclone.org/) 花了快一周时间才将其全部上传到阿里云盘。但是还是上传失败了好一部分，并且比较难确定是哪些遗失了。

后者量较少，但是对于安全保密性较高，我写了一个「导出-压缩-加密-上传-通知」的脚本，在 NAS 中以定时任务的形式每天进行全量备份。并且保存了近一年的历史备份。这对安全性要求较高的场景来说，不失为一个较为简单的方法，我将脚本分享在这里，大家改改应该就能直接用：

```shell
#!/bin/bash
source ~/.bashrc
# 记录开始时间
start_time=$(date +%s)

docker exec MySQL-9 sh -c 'exec mysqldump --databases traccar -u root -p"$MYSQL_ROOT_PASSWORD"' > /mnt/user/UNRAID/backup/TraccarBackup/Traccar.sql

# 生成文件名
file_name="Traccar`date +%Y%m%d%H%M%S`.7z"

# 将文件使用7z加密压缩，然后删除原始文件
7z a -p$ZIP_PASSWORD /mnt/user/UNRAID/backup/TraccarBackup/$file_name /mnt/user/UNRAID/backup/TraccarBackup/Traccar.sql

# 获取压缩文件的大小（单位：字节）
file_size=$(ls -lh /mnt/user/UNRAID/backup/TraccarBackup/$file_name | awk '{print $5}')

rm /mnt/user/UNRAID/backup/TraccarBackup/Traccar.sql

if [ $? -eq 0 ]; then

    find /mnt/user/UNRAID/backup/TraccarBackup/ -type f -ctime +365 | xargs rm -rf

    docker exec Nacho-Rclone-Native-GUI rclone sync /data/backup/TraccarBackup AList:/AliyunDrive/阿里云盘/Backup/NAS-Backup/TraccarBackup
    result_AliyunDrive=$?

    docker exec Nacho-Rclone-Native-GUI rclone sync /data/backup/TraccarBackup AList:/Quark/backup/NAS-Backup/TraccarBackup
    result_Quark=$?

    # 将result_AliyunDrive和result_Quark的值存入数组
    result_array=($result_AliyunDrive $result_Quark)

    # 记录结束时间
    end_time=$(date +%s)

    # 计算运行时间
    run_time=$((end_time - start_time))

    # 通知标题
    notification_title="TraccarBackup-NAS备份"
    # 通知内容
    notification_content="TraccarBackup-NAS备份，文件大小为$file_size"
    # 结果变量，用于存储成功数量
    success_count=0

    # 根据result_array循环，拼接通知内容
    for result in ${result_array[@]}; do
        if [ $result -eq 0 ]; then
            success_count=$((success_count + 1))
        fi
    done

    # 计算成功率，
    if [ ${#result_array[@]} -eq 0 ]; then
        success_rate=0
    else
        success_rate=$((success_count * 100 / ${#result_array[@]}))
    fi

    # 判断success_count是否等于result_array的长度
    if [ $success_count -eq ${#result_array[@]} ]; then
        notification_title="$notification_title全部成功✅"
    elif [ $success_count -eq 0 ]; then
        notification_title="$notification_title全部失败❌"
    else
        notification_title="$notification_title部分成功🟡"
    fi

    # 拼接通知内容
    notification_content="$notification_content，上传网盘：$success_count/${#result_array[@]}，成功率：$success_rate%，运行时间：$run_time 秒"

    # 对 notification_title 和 notification_content 进行 URL 编码
    encoded_title=$(echo "$notification_title" | jq -sRr @uri)
    encoded_content=$(echo "$notification_content" | jq -sRr @uri)

    # 发送通知
    curl "$BARK_SERVER/$BARK_KEY/$encoded_title/$encoded_content?group=TraccarBackup&icon=https://cdn.jsdelivr.net/gh/walkxcode/dashboard-icons/png/traccar.png"
fi

exit $?
```

需要注意的是上传部分使用了 AList 挂载了云盘，并使用 rclone 通过了 WebDAV 服务（照片部分的网盘上传也是通过这一途径）。

同上上述的脚本进行的备份，由于进行了压缩加密，可以在上传到第三方网盘的同时保证其隐私安全性，当然千万不要忘记压缩密码，不然数据虽在，但是可能永远都看不了了。

缺点也较为明显，只适用于较为小的文件备份，对于大文件的备份，由于需要加密压缩的原因，会导致最后压缩文件较大，不宜进行频繁备份。

这里再放上一个最近修改过的脚本，支持一次备份多个项目的文件：

```shell
#!/bin/bash

# --- 脚本配置 ---
# 确保这些环境变量已在您的 ~/.bashrc 文件中设置，或在一个专门的配置文件中设置
# 或者，如果您倾向于此方式，可以直接在此处定义（对于密码而言不太安全）
# 必需: ZIP_PASSWORD, MYSQL_ROOT_PASSWORD (如果使用MySQL), BARK_SERVER, BARK_KEY
source ~/.bashrc

# --- 全局设置 ---
MAIN_BACKUP_ROOT_HOST="/mnt/user/UNRAID/backup" # unRAID 主机上的备份根目录
RCLONE_DOCKER_CONTAINER="Nacho-Rclone-Native-GUI" # Rclone Docker 容器的名称
# MAIN_BACKUP_ROOT_HOST 在 RCLONE_DOCKER_CONTAINER 内部的映射路径
# 您的 rclone sync 命令使用 /data/backup/... 所以这里应该是 /data/backup
RCLONE_MOUNT_PREFIX_IN_CONTAINER="/data/backup"
DAYS_TO_KEEP_BACKUPS=365 # 本地备份文件保留天数
GLOBAL_START_TIME=$(date +%s) # 脚本全局开始时间
SCRIPT_VERSION="1.2-zh" # 脚本版本
# --- 日志文件 ---
# 暂不需要
# LOG_FILE="/mnt/user/UNRAID/your_script_name.log"

# --- 云盘远程配置 ---
# 在此定义您的 rclone 远程目标。键是易于识别的名称，值是 "rclone远程配置名:路径前缀"
declare -A CLOUD_REMOTES
CLOUD_REMOTES=(
    ["阿里云盘"]="AList:/AliyunDrive/阿里云盘/Backup/NAS-Backup" # 示例：阿里云盘
    ["夸克网盘"]="AList:/Quark/backup/NAS-Backup"         # 示例：夸克网盘
)

# --- 服务备份定义 ---
# 每个服务是一个关联数组。在此处添加新服务。
# 每个服务的参数说明:
#   name:                     (字符串) 用于通知和日志的人类可读名称。
#   type:                     (字符串) 备份类型: "mysql", "postgres", "folder"。
#   enabled:                  (布尔字符串) "true" 或 "false"，用于启用/禁用此服务的备份。
#   # 针对 type="mysql":
#   mysql_container:          (字符串) 运行 MySQL 的 Docker 容器名称。
#   db_name:                  (字符串) 需要转储的数据库名称。
#   raw_dump_filename:        (字符串) SQL 转储文件的临时文件名 (例如: "db.sql")。
#   # 针对 type="postgres":
#   pg_compose_file:          (字符串) docker-compose.yml 文件的路径。
#   pg_compose_service:       (字符串) docker-compose.yml 中 PostgreSQL 数据库服务的名称。
#   pg_db_user:               (字符串) PostgreSQL 用户名。
#   pg_db_name:               (字符串) PostgreSQL 数据库名称。
#   raw_dump_filename:        (字符串) 原始备份文件的临时文件名 (例如: "db.bck")。
#   # 针对 type="folder":
#   folder_to_backup_host:    (字符串) 主机上需要备份的文件夹的绝对路径。
#   stop_start_container:     (字符串, 可选) 备份前停止、备份后启动的容器名称。
#   # 所有类型通用:
#   local_backup_subdir:      (字符串) 在 MAIN_BACKUP_ROOT_HOST 下为此服务创建的备份子目录。
#   archive_prefix:           (字符串) 最终 .7z 归档文件名的前缀 (例如: "Gitea")。
#   bark_group:               (字符串) Bark 通知的群组名称。

declare -A GITEA_CONFIG=(
    [name]="Gitea"
    [type]="mysql"
    [enabled]="true"
    [mysql_container]="MySQL-9"
    [db_name]="gitea"
    [raw_dump_filename]="Gitea.sql"
    [local_backup_subdir]="GiteaBackup"
    [archive_prefix]="Gitea"
    [bark_group]="Backup" # Bark 分组名
)

declare -A TESLAMATE_CONFIG=(
    [name]="TeslaMate"
    [type]="postgres"
    [enabled]="true"
    [pg_compose_file]="/boot/config/plugins/compose.manager/projects/TeslaMate/docker-compose.yml"
    [pg_compose_service]="database"
    [pg_db_user]="teslamate"
    [pg_db_name]="teslamate"
    [raw_dump_filename]="teslamate.bck"
    [local_backup_subdir]="TeslaMateBackup"
    [archive_prefix]="teslamate"
    [bark_group]="TeslamateBackup"
)

declare -A TRACCAR_CONFIG=(
    [name]="Traccar"
    [type]="mysql"
    [enabled]="true"
    [mysql_container]="MySQL-9"
    [db_name]="traccar"
    [raw_dump_filename]="Traccar.sql"
    [local_backup_subdir]="TraccarBackup"
    [archive_prefix]="Traccar"
    [bark_group]="TraccarBackup"
)

declare -A VAULTWARDEN_CONFIG=(
    [name]="VaultWarden (密码管理器)"
    [type]="folder"
    [enabled]="true"
    [folder_to_backup_host]="/mnt/user/appdata/vaultwarden"
    [stop_start_container]="VaultWarden" # 确保这是精确的容器名
    [local_backup_subdir]="VaultWardenBackup"
    [archive_prefix]="VaultWarden"
    [bark_group]="VaultWardenBackup"
)

declare -A WAKAPI_CONFIG=(
    [name]="WakAPI (编程时长统计)"
    [type]="mysql"
    [enabled]="true"
    [mysql_container]="MySQL-9"
    [db_name]="wakapi"
    [raw_dump_filename]="WakAPI.sql"
    [local_backup_subdir]="WakAPIBackup"
    [archive_prefix]="WakAPI"
    [bark_group]="WakAPIBackup"
)

declare -A QIANDAO_CONFIG=(
    [name]="自动签到服务"
    [type]="mysql"
    [enabled]="true"
    [mysql_container]="MySQL-9"
    [db_name]="qiandao"
    [raw_dump_filename]="qiandao.sql"
    [local_backup_subdir]="自动签到备份" # 目录名保持原样，以便兼容旧备份
    [archive_prefix]="qiandao"
    [bark_group]="自动签到备份" # Bark 分组名保持原样
)

declare -A TIEBA_CONFIG=(
    [name]="贴吧云签到"
    [type]="mysql"
    [enabled]="true"
    [mysql_container]="MySQL-9"
    [db_name]="tiebacloud"
    [raw_dump_filename]="Tieba-Cloud-Sign.sql"
    [local_backup_subdir]="贴吧云签到备份" # 目录名保持原样
    [archive_prefix]="Tieba-Cloud-Sign"
    [bark_group]="贴吧云签到备份" # Bark 分组名保持原样
)

# --- 备份顺序 ---
# 在此按期望的执行顺序列出上面定义的服务配置数组的名称。
# 例如: "GITEA_CONFIG", "TESLAMATE_CONFIG" 等。
BACKUP_ORDER=(
    "GITEA_CONFIG"
    "TESLAMATE_CONFIG"
    "TRACCAR_CONFIG"
    "VAULTWARDEN_CONFIG"
    "WAKAPI_CONFIG"
    "QIANDAO_CONFIG"
    "TIEBA_CONFIG"
)

# --- 用于汇总的全局变量 ---
declare -a SUMMARY_LINES # 存储每个任务的摘要信息
TOTAL_JOBS=0 # 总任务数
SUCCESSFUL_JOBS=0 # 成功任务数

# --- 辅助函数 ---
log_message() {
    local message_content="$1"
    local timestamp
    timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    local formatted_message="${timestamp} - ${message_content}"

    # 输出到标准错误 (stderr)
    printf "%s\n" "${formatted_message}" >&2

    # 追加输出到日志文件
    # 确保 LOG_FILE 变量已定义并且脚本对该文件有写入权限
    if [ -n "$LOG_FILE" ]; then
        echo "${formatted_message}" >> "$LOG_FILE"
        # 可以添加一个检查，看写入是否成功，但通常 >> 如果失败会静默或由系统层面报错
        # if [ $? -ne 0 ]; then
        #     printf "%s - %s\n" "$(date '+%Y-%m-%d %H:%M:%S')" "警告: 写入日志文件 ${LOG_FILE} 失败！" >&2
        # fi
    # else
    #     printf "%s - %s\n" "$(date '+%Y-%m-%d %H:%M:%S')" "警告: LOG_FILE 未定义，无法写入文件日志。" >&2
    fi
}

# URL 编码 (用于 Bark 通知)
url_encode() {
    echo "$1" | jq -sRr @uri
}

# --- 核心逻辑函数 ---

# 转储 MySQL 数据库
# 参数: $1: mysql_container, $2: db_name, $3: output_dump_path (转储文件输出路径)
dump_mysql() {
    local mysql_container="$1"
    local db_name="$2"
    local output_dump_path="$3"
    log_message "正在从容器 '$mysql_container' 转储 MySQL 数据库 '$db_name' 到 '$output_dump_path'..."
    if docker exec "$mysql_container" sh -c "exec mysqldump --databases \"$db_name\" -u root -p\"\$MYSQL_ROOT_PASSWORD\"" > "$output_dump_path"; then
        log_message "MySQL 数据库 '$db_name' 转储成功。"
        return 0
    else
        log_message "错误：MySQL 数据库 '$db_name' 转储失败。"
        rm -f "$output_dump_path" # 清理可能产生的损坏转储文件
        return 1
    fi
}

# 转储 PostgreSQL 数据库
# 参数: $1: pg_compose_file, $2: pg_compose_service, $3: pg_db_user, $4: pg_db_name, $5: output_dump_path
dump_postgres() {
    local pg_compose_file="$1"
    local pg_compose_service="$2"
    local pg_db_user="$3"
    local pg_db_name="$4"
    local output_dump_path="$5"
    log_message "正在从 Compose 服务 '$pg_compose_service' (用户 '$pg_db_user') 转储 PostgreSQL 数据库 '$pg_db_name' 到 '$output_dump_path'..."
    if /usr/local/bin/docker-compose -f "$pg_compose_file" exec -T "$pg_compose_service" pg_dump -U "$pg_db_user" "$pg_db_name" > "$output_dump_path"; then
        log_message "PostgreSQL 数据库 '$pg_db_name' 转储成功。"
        return 0
    else
        log_message "错误：PostgreSQL 数据库 '$pg_db_name' 转储失败。"
        rm -f "$output_dump_path" # 清理可能产生的损坏转储文件
        return 1
    fi
}

# 压缩文件或文件夹，并可选删除源文件
# 参数: $1: archive_output_path (完整 .7z 归档路径), $2: source_to_compress (待压缩的文件或文件夹), $3: (可选) raw_dump_file_to_delete (待删除的原始转储文件)
compress_backup() {
    local archive_output_path="$1"
    local source_to_compress="$2"
    local raw_dump_file_to_delete="${3:-}" # 如果未提供，则默认为空

    log_message "正在将 '$source_to_compress' 压缩到 '$archive_output_path'..."
    if 7z a -p"$ZIP_PASSWORD" "$archive_output_path" "$source_to_compress"; then
        log_message "压缩成功。"
        if [ -n "$raw_dump_file_to_delete" ] && [ -f "$raw_dump_file_to_delete" ]; then
            log_message "正在删除原始转储文件 '$raw_dump_file_to_delete'..."
            rm "$raw_dump_file_to_delete"
        fi
        return 0
    else
        log_message "错误：压缩 '$source_to_compress' 失败。"
        return 1
    fi
}

# 清理指定目录下的旧备份归档文件
# 参数: $1: directory_to_clean (待清理的目录)
cleanup_old_archives() {
    local directory_to_clean="$1"
    log_message "正在清理 '$directory_to_clean' 目录下超过 $DAYS_TO_KEEP_BACKUPS 天的旧备份..."
    find "$directory_to_clean" -type f -name "*.7z" -mtime "+$DAYS_TO_KEEP_BACKUPS" -print -delete
    log_message "旧备份清理完成。"
}

# 将备份同步到已配置的云盘远程目标
# 参数: $1: local_backup_subdir_name (例如 GiteaBackup), $2: service_name_for_log (用于日志的服务名)
sync_to_cloud() {
    local local_backup_subdir_name="$1"
    local service_name_for_log="$2"

    local rclone_source_path_in_container="${RCLONE_MOUNT_PREFIX_IN_CONTAINER}/${local_backup_subdir_name}"
    local successful_syncs=0
    local total_syncs=0
    local sync_results_summary=""

    for remote_friendly_name in "${!CLOUD_REMOTES[@]}"; do
        total_syncs=$((total_syncs + 1))
        local rclone_dest_full_path="${CLOUD_REMOTES[$remote_friendly_name]}/${local_backup_subdir_name}"
        log_message "正在将 '${service_name_for_log}' 的备份从容器内路径 '$rclone_source_path_in_container' 同步到 ${remote_friendly_name} ('$rclone_dest_full_path')..."
        if docker exec "$RCLONE_DOCKER_CONTAINER" rclone sync "$rclone_source_path_in_container" "$rclone_dest_full_path"; then
            log_message "Rclone 同步 '${service_name_for_log}' 到 ${remote_friendly_name} 成功。"
            successful_syncs=$((successful_syncs + 1))
            sync_results_summary+="${remote_friendly_name}: ✅; "
        else
            log_message "错误：Rclone 同步 '${service_name_for_log}' 到 ${remote_friendly_name} 失败。"
            sync_results_summary+="${remote_friendly_name}: ❌; "
        fi
    done

    # 移除末尾的 "; "
    sync_results_summary="${sync_results_summary%; *}"
    echo "$successful_syncs/$total_syncs|$sync_results_summary" # 返回成功数/总数和摘要字符串
}


# --- 处理单个服务的主函数 ---
# 参数: 传入服务配置的关联数组名称 (例如 "GITEA_CONFIG")
process_one_service() {
    local service_config_name="$1"
    declare -n config_ref="$service_config_name" # 使用 nameref 引用服务的配置数组

    TOTAL_JOBS=$((TOTAL_JOBS + 1))
    local job_start_time=$(date +%s)
    local job_status_icon="❌" # 默认为失败图标
    local job_summary_line=""
    local final_archive_path=""
    local archive_file_size_human=""

    log_message "--- 开始备份服务: ${config_ref[name]} ---"

    if [ "${config_ref[enabled]}" != "true" ]; then
        log_message "服务 ${config_ref[name]} 已禁用，跳过。"
        job_summary_line="⚪ ${config_ref[name]}: 已跳过"
        SUMMARY_LINES+=("$job_summary_line")
        # 对于跳过的任务，不计入 SUCCESSFUL_JOBS，但也不算作整体失败
        return
    fi

    local host_service_backup_dir="${MAIN_BACKUP_ROOT_HOST}/${config_ref[local_backup_subdir]}"
    mkdir -p "$host_service_backup_dir" #确保备份子目录存在

    local archive_filename_dated="${config_ref[archive_prefix]}$(date +%Y%m%d%H%M%S).7z"
    final_archive_path="${host_service_backup_dir}/${archive_filename_dated}"

    local dump_success=false # 转储/准备是否成功
    local compress_success=false # 压缩是否成功
    local raw_dump_full_path="" # 原始转储文件的完整路径

    # 步骤 1: 执行备份 (转储数据库 或 准备文件夹)
    case "${config_ref[type]}" in
        mysql)
            raw_dump_full_path="${host_service_backup_dir}/${config_ref[raw_dump_filename]}"
            if dump_mysql "${config_ref[mysql_container]}" "${config_ref[db_name]}" "$raw_dump_full_path"; then
                dump_success=true
            fi
            ;;
        postgres)
            raw_dump_full_path="${host_service_backup_dir}/${config_ref[raw_dump_filename]}"
            if dump_postgres "${config_ref[pg_compose_file]}" "${config_ref[pg_compose_service]}" "${config_ref[pg_db_user]}" "${config_ref[pg_db_name]}" "$raw_dump_full_path"; then
                dump_success=true
            fi
            ;;
        folder)
            # 对于文件夹类型，可能需要先停止容器
            if [ -n "${config_ref[stop_start_container]}" ]; then
                local container_id # 存储容器ID
                # 使用 ^...$ 来精确匹配容器名，避免部分匹配
                container_id=$(docker ps -q -f name="^${config_ref[stop_start_container]}$")
                if [ -n "$container_id" ]; then
                    log_message "正在停止容器 ${config_ref[stop_start_container]} (ID: $container_id)..."
                    if ! docker stop "$container_id"; then
                         log_message "错误：停止容器 ${config_ref[stop_start_container]} 失败。中止此服务的备份。"
                         job_summary_line="❌ ${config_ref[name]}: 失败 (停止容器时出错)"
                         SUMMARY_LINES+=("$job_summary_line")
                         return # 中止此服务的处理
                    fi
                else
                    log_message "警告：未找到或未运行名为 ${config_ref[stop_start_container]} 的容器。继续执行备份。"
                    # 即使容器未找到，也可能希望继续备份文件夹（如果文件夹独立于容器运行状态）
                fi
            fi

            # 对于文件夹类型，压缩步骤即为备份创建步骤
            if compress_backup "$final_archive_path" "${config_ref[folder_to_backup_host]}"; then
                compress_success=true # 对于文件夹类型，dump_success 不适用，compress_success 是关键
            fi

            # 如果之前停止了容器，现在重新启动它
            if [ -n "${config_ref[stop_start_container]}" ] && [ -n "$container_id" ]; then # 仅当找到并停止了容器时才启动
                log_message "正在启动容器 ${config_ref[stop_start_container]} (ID: $container_id)..."
                if ! docker start "$container_id"; then
                    log_message "错误：备份后启动容器 ${config_ref[stop_start_container]} 失败。请手动检查。"
                    # 即使启动失败，备份本身可能已成功，所以继续报告
                fi
            fi
            ;;
        *)
            log_message "错误：服务 ${config_ref[name]} 的备份类型 '${config_ref[type]}' 未知。"
            job_summary_line="❌ ${config_ref[name]}: 失败 (未知备份类型)"
            SUMMARY_LINES+=("$job_summary_line")
            return # 中止此服务的处理
            ;;
    esac

    # 步骤 2: 压缩 (如果是数据库转储类型)
    if [[ "${config_ref[type]}" == "mysql" || "${config_ref[type]}" == "postgres" ]]; then
        if $dump_success; then
            if compress_backup "$final_archive_path" "$raw_dump_full_path" "$raw_dump_full_path"; then
                compress_success=true
            fi
        else
            log_message "由于 '${config_ref[name]}' 的数据库转储失败，跳过压缩步骤。"
        fi
    fi

    # 步骤 3: 压缩后的操作 (清理旧备份, 同步到云端)
    if $compress_success; then
        # 获取压缩文件大小
        archive_file_size_bytes=$(stat -c%s "$final_archive_path") # 获取字节数，用于可能的进一步处理
        archive_file_size_human=$(ls -lh "$final_archive_path" | awk '{print $5}') # 人类可读的大小
        log_message "归档文件已创建: $final_archive_path, 大小: $archive_file_size_human"

        cleanup_old_archives "$host_service_backup_dir" # 清理此服务旧的本地备份

        # 同步到云端
        cloud_sync_result_str=$(sync_to_cloud "${config_ref[local_backup_subdir]}" "${config_ref[name]}")

        # debug
        log_message "debug 云同步结果: $cloud_sync_result_str"

        # 使用 cut 分割结果字符串（更简单且避免SC2086 shellcheck警告）
        cloud_sync_counts=$(echo "$cloud_sync_result_str" | cut -d'|' -f1)
        cloud_sync_details=$(echo "$cloud_sync_result_str" | cut -d'|' -f2)

        #debug
        log_message "debug 云同步统计: $cloud_sync_counts, 详细信息: $cloud_sync_details"

        successful_cloud_syncs=$(echo "$cloud_sync_counts" | cut -d'/' -f1)
        total_cloud_syncs=$(echo "$cloud_sync_counts" | cut -d'/' -f2)

        # debug
        log_message "debug 云同步统计: 成功 $successful_cloud_syncs, 总计 $total_cloud_syncs"

        if [ "$successful_cloud_syncs" -eq "$total_cloud_syncs" ] && [ "$total_cloud_syncs" -gt 0 ]; then
            job_status_icon="✅" # 所有云端同步成功
            SUCCESSFUL_JOBS=$((SUCCESSFUL_JOBS + 1)) # 此任务计为成功
        elif [ "$successful_cloud_syncs" -gt 0 ]; then
            job_status_icon="🟡" # 部分云端同步成功
            # 根据需求，部分成功也可以计入 SUCCESSFUL_JOBS
            # SUCCESSFUL_JOBS=$((SUCCESSFUL_JOBS + 1))
        else
            job_status_icon="❌" # 云端同步完全失败或未配置远程目标
        fi

        job_summary_line="${job_status_icon} ${config_ref[name]}: (大小: ${archive_file_size_human}, 云同步: ${cloud_sync_details})"

    else # 压缩失败或因先前错误跳过压缩
        job_status_icon="❌"
        if [[ "${config_ref[type]}" == "mysql" || "${config_ref[type]}" == "postgres" ]]; then
            if ! $dump_success; then # 如果是转储失败
                job_summary_line="${job_status_icon} ${config_ref[name]}: (数据库转储失败)"
            else # 如果是转储成功但压缩失败
                 job_summary_line="${job_status_icon} ${config_ref[name]}: (压缩失败)"
            fi
        elif [[ "${config_ref[type]}" == "folder" ]]; then # 如果是文件夹类型且压缩失败
             job_summary_line="${job_status_icon} ${config_ref[name]}: (归档创建失败)"
        fi
    fi

    local job_end_time=$(date +%s)
    local job_run_time=$((job_end_time - job_start_time))
    job_summary_line+=" - ${job_run_time}秒" # 附加任务运行时长

    SUMMARY_LINES+=("$job_summary_line") # 将此任务的摘要添加到全局列表
    log_message "--- 完成服务备份: ${config_ref[name]}。结果: ${job_summary_line} ---"
}


# --- 主执行流程 ---
log_message "=== Docker 服务备份脚本 v${SCRIPT_VERSION} 已启动 ==="

# 检查必需的工具
for tool in docker 7z jq curl stat; do
    if ! command -v $tool &> /dev/null; then
        log_message "错误：必需工具 '$tool' 未安装。请安装后再试。"
        # 尝试发送关于此严重错误的 Bark 基本通知
        if [ -n "$BARK_SERVER" ] && [ -n "$BARK_KEY" ]; then
            # 避免在URL中直接包含可能导致问题的字符，进行简单替换或移除
            error_tool_msg="必需工具 '$tool' 未找到。脚本中止。"
            encoded_error_title=$(url_encode "Docker备份严重错误")
            encoded_error_content=$(url_encode "$error_tool_msg")
            curl -sS "$BARK_SERVER/$BARK_KEY/$encoded_error_title/$encoded_error_content" > /dev/null
        fi
        exit 1
    fi
done

# 检查基本的环境变量
missing_vars=()
[ -z "$ZIP_PASSWORD" ] && missing_vars+=("ZIP_PASSWORD (压缩密码)")
# MYSQL_ROOT_PASSWORD 仅在启用了 MySQL 任务时才需要。稍后检查或用户自行确保。
[ -z "$BARK_SERVER" ] && missing_vars+=("BARK_SERVER (Bark服务器地址)")
[ -z "$BARK_KEY" ] && missing_vars+=("BARK_KEY (Bark设备密钥)")

if [ ${#missing_vars[@]} -gt 0 ]; then
    error_vars_msg="错误：以下环境变量未设置: ${missing_vars[*]}. 请在 ~/.bashrc 或脚本中设置它们。"
    log_message "$error_vars_msg"
    # 尝试发送 Bark 通知
     if [ -n "$BARK_SERVER" ] && [ -n "$BARK_KEY" ]; then # 再次检查，以防部分变量缺失
        encoded_error_title=$(url_encode "Docker备份配置错误")
        encoded_error_content=$(url_encode "环境变量缺失: ${missing_vars[*]}. 脚本中止。")
        curl -sS "$BARK_SERVER/$BARK_KEY/$encoded_error_title/$encoded_error_content" > /dev/null
    fi
    exit 1
fi


# 遍历 BACKUP_ORDER 数组中定义的服务，并依次处理
for service_config_ref_name in "${BACKUP_ORDER[@]}"; do
    process_one_service "$service_config_ref_name"
done

GLOBAL_END_TIME=$(date +%s)
TOTAL_RUN_TIME=$((GLOBAL_END_TIME - GLOBAL_START_TIME)) # 计算总运行时长

# --- 汇总通知 ---
notification_title_prefix="NAS Docker 服务备份" # 通知标题前缀
notification_title="" # 最终通知标题
notification_content_detail="" # 通知内容的详细部分

if [ "$TOTAL_JOBS" -eq 0 ]; then
    notification_title="${notification_title_prefix} - 未定义任务 🤷"
    notification_content_detail="没有配置或启用任何备份任务。"
else
    if [ "$SUCCESSFUL_JOBS" -eq "$TOTAL_JOBS" ]; then
        notification_title="${notification_title_prefix} - 全部成功 ✅"
    elif [ "$SUCCESSFUL_JOBS" -gt 0 ]; then
        notification_title="${notification_title_prefix} - 部分成功 🟡"
    else
        notification_title="${notification_title_prefix} - 全部失败 ❌"
    fi

    # 构建详细内容
    for line in "${SUMMARY_LINES[@]}"; do
        notification_content_detail+="${line}\n\n" # Bark 中使用 \n 换行
    done
    # 移除最后一个多余的换行符
    notification_content_detail=$(echo -e "${notification_content_detail%\\n\\n}")
fi

notification_content_summary="汇总: ${SUCCESSFUL_JOBS}/${TOTAL_JOBS} 个任务成功。总耗时: ${TOTAL_RUN_TIME}秒。"

# 组合摘要和详情作为 Bark 通知内容
final_notification_content="${notification_content_summary} 详情:

${notification_content_detail}"

log_message "脚本运行完毕。$notification_content_summary"
log_message "正在发送整合的 Bark 通知..."

# 为主通知使用通用图标或第一个服务的图标
# 或者，您可以定义一个全局图标URL
main_notification_icon_url="https://cdn.jsdelivr.net/gh/xushier/HD-Icons/border-radius/Unraid_A.png"

encoded_title=$(url_encode "$notification_title")
encoded_content=$(url_encode "$final_notification_content") # 确保这里用的是 final_notification_content

bark_url="${BARK_SERVER}/${BARK_KEY}/${encoded_title}/${encoded_content}?group=NASDockerBackup&icon=${main_notification_icon_url}"

if curl -sS --fail --connect-timeout 10 --max-time 30 "$bark_url"; then # 增加超时设置并检查HTTP错误
    log_message "Bark 通知已成功发送。"
else
    log_message "错误：发送 Bark 通知失败。请检查 Bark 服务器地址、密钥以及网络连接。URL: ${bark_url}"
fi

log_message "=== Docker 服务备份脚本执行完毕。总耗时: ${TOTAL_RUN_TIME}秒 ==="

# 如果并非所有已尝试的任务都成功，则以错误码退出 (跳过的任务不计入失败)
if [ "$SUCCESSFUL_JOBS" -lt "$TOTAL_JOBS" ]; then
    # 如果有任务被配置为执行 (enabled=true) 但失败了
    actual_attempted_jobs=0
    for cfg_name in "${BACKUP_ORDER[@]}"; do
        declare -n cfg="$cfg_name"
        if [[ "${cfg[enabled]}" == "true" ]]; then
            actual_attempted_jobs=$((actual_attempted_jobs + 1))
        fi
    done
    if [ "$SUCCESSFUL_JOBS" -lt "$actual_attempted_jobs" ]; then
        log_message "部分或全部已启用的备份任务失败。脚本以错误状态退出。"
        exit 1
    fi
fi

exit 0 # 所有已启用的任务都成功，或没有启用任务
```

### 第二版备份方案

以下就是我写这一篇文章的契机，在某一次冲浪时，接触到了一款叫 [restic](https://restic.net/) 的开源软件。在使用后我发现，它完美解决了第一版备份中遇到的问题。例如安全性保证，大量文件的增量备份，甚至它还能提供版本管理！称它为完美的备份软件也不为过。

当然事物都有其两面性，restic 是一款没有图形界面的工具，要想使用它得了解一些额外的知识。

当然事物都有其两面性，既然它这么好用，那说不定会有人为它开发图形界面呢？这就是今天的主角：[Backrest](https://github.com/garethgeorge/backrest)。

官网是这么介绍它的：

> Backrest is a web-accessible backup solution built on top of restic.

Backrest 是一个构建于 Restic 之上的可通过网页访问的备份解决方案。

通过 Backrest 我们就可以用较为简单的方式来使用 restic 备份文件。

#### 安装 Backrest

我们可以通过 Docker 来安装 Backrest。安装命令如下：

```shell
docker run -d \
  --name backrest \                                      # 容器名称
  --net bridge \                                         # 使用默认的桥接网络模式
  --pids-limit 2048 \                                    # 限制最大进程数为 2048
  -p 9898:9898/tcp \                                     # 映射主机端口 9898 到容器端口 9898
  -e TZ="Asia/Shanghai" \                                # 设置时区
  -e BACKREST_DATA="/data" \                             # Backrest 数据目录环境变量
  -e BACKREST_CONFIG="/config/config.json" \             # Backrest 配置文件路径
  -e XDG_CACHE_HOME="/cache" \                           # 缓存目录路径
  -v /mnt/user/appdata/backrest:/config:rw \             # 映射配置文件目录
  -v /mnt/user/appdata/backrest/cache:/cache:rw \        # 映射缓存目录
  -v /mnt/user/appdata/backrest/data:/data:rw \          # 映射数据目录
  -v /mnt/user/appdata/backrest/repos:/repos:rw \        # 映射备份仓库目录
  -v /mnt/user:/backup:ro \                              # 映射只读的备份源目录
  -v /mnt/user/appdata/rclone:/root/.config/rclone:rw \  # 映射 rclone 配置目录
  garethgeorge/backrest:latest                           # 使用的镜像名称
```

上述命令在使用时需要去除注释并按照自身情况修改映射的目录和端口。

需要注意的有：

1. `-v /mnt/user:/backup:ro` 这部分是只读（ro），当需要恢复文件时，这部分可以临时修改为读写（rw），或者挂载另外一个恢复目录，由于大部分时间还是读为主，所以这里为了源数据安全考虑，还是写成只读会好一些；

2. `-v /mnt/user/appdata/rclone:/root/.config/rclone:rw` 由于我的备份目的地是 rclone，所以这里需要传入 rclone 的备份文件，当在 Backrest 配置了目的地为 rclone 的仓库时，restic 就会从这里进行读取信息。

#### 创建用户

这时我们访问宿主机的 `9898` 端口，就可以看到 Backrest 的图形界面了。

![Backrest界面1.png](https://cdn.jsdelivr.net/gh/AemonCao/AemonCao.github.io@master/source/_posts/榨干这台NAS第006话-关于备份/Backrest界面1.png)

你需要输入一个实例ID，并创建一个用户。

#### 创建仓库（repository）

在 restic 中，保存备份的地方就叫做 repository。和 git 中的 repository 一样，它是一个目录，包含一些由 restic 创建的一级目录和文件。里面存储着你的备份文件、元数据以及加密密钥。

点击页面左侧菜单的 *Add Repo* （图中 1 部分）即可打开创建仓库的表单：

![Backrest界面2.png](https://cdn.jsdelivr.net/gh/AemonCao/AemonCao.github.io@master/source/_posts/榨干这台NAS第006话-关于备份/Backrest界面2.png)

首先输入仓库名称（图中 2 部分），这部分不支持中文，也不支持空格，你可以按照备份目的地和备份内容来进行取名，比如我的备份目的地是 123 网盘，备份内容是 NAS 的文件，所以我的仓库名叫做 *123CloudNASBackup*。

然后是 Repository URI（图中 3 部分），这是 restic 较为关键的部分，可以把他当作连接到备份目的地的地址，这一部分根据你实际的备份目的地的不同，格式也不同。下面是一些常用的备份目的地类型：

| 存储库类型     | 存储库 URL 示例                                                                                             | 备注（字段含义）                                                                                          |
|----------------|--------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|
| 本地文件系统   | `/srv/restic-repo`                                                                                          | 本地路径作为存储库                                                                                       |
| SFTP           | `sftp:user@host:/srv/restic-repo`                                                                            | `user` 是用户名，`host` 是远程主机，路径为远程目录                                                      |
| REST 服务器    | `rest:http://host:8000/`<br>`rest:https://user:pass@host:8000/`<br>`rest:https://user:pass@host:8000/my_backup_repo/`<br>`rest:http+unix:///tmp/rest.socket:/my_backup_repo/` | 支持 HTTP/HTTPS 或 Unix socket；可包含用户名密码、端口、路径等信息                                      |
| Amazon S3      | `s3:s3.us-east-1.amazonaws.com/bucket_name`                                                                  | `s3.us-east-1.amazonaws.com` 是区域端点，`bucket_name` 是存储桶名称                                      |
| Rclone         | `rclone:foo:bar`                                                                                             | `foo` 是 Rclone 配置中的远程名，`bar` 是远程路径                                                         |

未完待续
